{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roixiao/x-research-skill/blob/main/whisper_youtube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Youtube Videos Transcription with OpenAI's Whisper**\n",
        "\n",
        "[![blog post shield](https://img.shields.io/static/v1?label=&message=Blog%20post&color=blue&style=for-the-badge&logo=openai&link=https://openai.com/blog/whisper)](https://openai.com/blog/whisper)\n",
        "[![notebook shield](https://img.shields.io/static/v1?label=&message=Notebook&color=blue&style=for-the-badge&logo=googlecolab&link=https://colab.research.google.com/github/ArthurFDLR/whisper-youtube/blob/main/whisper_youtube.ipynb)](https://colab.research.google.com/github/ArthurFDLR/whisper-youtube/blob/main/whisper_youtube.ipynb)\n",
        "[![repository shield](https://img.shields.io/static/v1?label=&message=Repository&color=blue&style=for-the-badge&logo=github&link=https://github.com/openai/whisper)](https://github.com/openai/whisper)\n",
        "[![paper shield](https://img.shields.io/static/v1?label=&message=Paper&color=blue&style=for-the-badge&link=https://cdn.openai.com/papers/whisper.pdf)](https://cdn.openai.com/papers/whisper.pdf)\n",
        "[![model card shield](https://img.shields.io/static/v1?label=&message=Model%20card&color=blue&style=for-the-badge&link=https://github.com/openai/whisper/blob/main/model-card.md)](https://github.com/openai/whisper/blob/main/model-card.md)\n",
        "\n",
        "Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.\n",
        "\n",
        "This Notebook will guide you through the transcription of a Youtube video using Whisper. You'll be able to explore most inference parameters or use the Notebook as-is to store the transcript and video audio in your Google Drive."
      ],
      "metadata": {
        "id": "96kvih9mXkNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Check GPU type** üïµÔ∏è\n",
        "\n",
        "#@markdown The type of GPU you get assigned in your Colab session defined the speed at which the video will be transcribed.\n",
        "#@markdown The higher the number of floating point operations per second (FLOPS), the faster the transcription.\n",
        "#@markdown But even the least powerful GPU available in Colab is able to run any Whisper model.\n",
        "#@markdown Make sure you've selected `GPU` as hardware accelerator for the Notebook (Runtime &rarr; Change runtime type &rarr; Hardware accelerator).\n",
        "\n",
        "#@markdown |  GPU   |  GPU RAM   | FP32 teraFLOPS |     Availability   |\n",
        "#@markdown |:------:|:----------:|:--------------:|:------------------:|\n",
        "#@markdown |  T4    |    16 GB   |       8.1      |         Free       |\n",
        "#@markdown | P100   |    16 GB   |      10.6      |      Colab Pro     |\n",
        "#@markdown | V100   |    16 GB   |      15.7      |  Colab Pro (Rare)  |\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Factory reset your Notebook's runtime if you want to get assigned a new GPU.**\n",
        "\n",
        "!nvidia-smi -L\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QshUbLqpX7L4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfG0E_WbRFI0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Install libraries** üèóÔ∏è\n",
        "#@markdown This cell will take a little while to download several libraries, including Whisper.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install yt-dlp\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "import whisper\n",
        "from pathlib import Path\n",
        "import yt_dlp\n",
        "import subprocess\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "from IPython.display import display, Markdown, YouTubeVideo\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zwGAsr4sIgd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Optional:** Save data in Google Drive üíæ\n",
        "#@markdown Enter a Google Drive path and run this cell if you want to store the results inside Google Drive.\n",
        "\n",
        "# Uncomment to copy generated images to drive, faster than downloading directly from colab in my experience.\n",
        "from google.colab import drive\n",
        "drive_mount_path = Path(\"/\") / \"content\" / \"drive\"\n",
        "drive.mount(str(drive_mount_path))\n",
        "drive_mount_path /= \"My Drive\"\n",
        "#@markdown ---\n",
        "drive_path = \"Colab Notebooks/Whisper Youtube\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change your Google Drive path.**\n",
        "\n",
        "drive_whisper_path = drive_mount_path / Path(drive_path.lstrip(\"/\"))\n",
        "drive_whisper_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Model selection** üß†\n",
        "\n",
        "#@markdown As of the first public release, there are 4 pre-trained options to play with:\n",
        "\n",
        "#@markdown |  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "#@markdown |:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
        "#@markdown |  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
        "#@markdown |  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
        "#@markdown | small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
        "#@markdown | medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
        "#@markdown | large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |\n",
        "\n",
        "#@markdown ---\n",
        "Model = 'medium' #@param ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large']\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the model.**\n",
        "\n",
        "whisper_model = whisper.load_model(Model)\n",
        "\n",
        "if Model in whisper.available_models():\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is selected.**\"\n",
        "    ))\n",
        "else:\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is no longer available.**<br /> Please select one of the following:<br /> - {'<br /> - '.join(whisper.available_models())}\"\n",
        "    ))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TMhrSq_GZ6kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Video selection** üì∫\n",
        "\n",
        "#@markdown Enter the URL of the Youtube video you want to transcribe, wether you want to save the audio file in your Google Drive, and run the cell.\n",
        "\n",
        "Type = \"Youtube video or playlist\" #@param ['Youtube video or playlist', 'Google Drive']\n",
        "#@markdown ---\n",
        "#@markdown #### **Youtube video or playlist**\n",
        "URL = \"https://youtu.be/r-37JtaWy-A?si=dMJIa3MP7F-i2I1b\" #@param {type:\"string\"}\n",
        "# store_audio = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #### **Google Drive video, audio (mp4, wav), or folder containing video and/or audio files**\n",
        "video_path = \"\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the video.**\n",
        "\n",
        "video_path_local_list = []\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'm4a/bestaudio/best',\n",
        "        'outtmpl': '%(id)s.%(ext)s',\n",
        "        # ‚ÑπÔ∏è See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments\n",
        "        'postprocessors': [{  # Extract audio using ffmpeg\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        error_code = ydl.download([URL])\n",
        "        list_video_info = [ydl.extract_info(URL, download=False)]\n",
        "\n",
        "    for video_info in list_video_info:\n",
        "        video_path_local_list.append(Path(f\"{video_info['id']}.wav\"))\n",
        "\n",
        "elif Type == \"Google Drive\":\n",
        "    # video_path_drive = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    video_path = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    if video_path.is_dir():\n",
        "        for video_path_drive in video_path.glob(\"**/*\"):\n",
        "            if video_path_drive.is_file():\n",
        "                display(Markdown(f\"**{str(video_path_drive)} selected for transcription.**\"))\n",
        "            elif video_path_drive.is_dir():\n",
        "                display(Markdown(f\"**Subfolders not supported.**\"))\n",
        "            else:\n",
        "                display(Markdown(f\"**{str(video_path_drive)} does not exist, skipping.**\"))\n",
        "            video_path_local = Path(\".\").resolve() / (video_path_drive.name)\n",
        "            shutil.copy(video_path_drive, video_path_local)\n",
        "            video_path_local_list.append(video_path_local)\n",
        "    elif video_path.is_file():\n",
        "        video_path_local = Path(\".\").resolve() / (video_path.name)\n",
        "        shutil.copy(video_path, video_path_local)\n",
        "        video_path_local_list.append(video_path_local)\n",
        "        display(Markdown(f\"**{str(video_path)} selected for transcription.**\"))\n",
        "    else:\n",
        "        display(Markdown(f\"**{str(video_path)} does not exist.**\"))\n",
        "\n",
        "else:\n",
        "    raise(TypeError(\"Please select supported input type.\"))\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "    if video_path_local.suffix == \".mp4\":\n",
        "        video_path_local = video_path_local.with_suffix(\".wav\")\n",
        "        result  = subprocess.run([\"ffmpeg\", \"-i\", str(video_path_local.with_suffix(\".mp4\")), \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", str(video_path_local)])\n"
      ],
      "metadata": {
        "id": "xYLPZQX9S7tU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X0qB9JAzMLY",
        "cellView": "form",
        "collapsed": true,
        "outputId": "f638a971-6742-41d5-b302-582fd5d64aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "data": {
            "text/markdown": "### L_Guz73e6fw.wav",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:04.000]  We have been a misunderstood and badly mocked org for a long time.\n",
            "[00:04.000 --> 00:05.000]  Like when we started,\n",
            "[00:07.500 --> 00:09.700]  we like announced the org at the end of 2015,\n",
            "[00:10.900 --> 00:12.400]  said we're going to work on AGI.\n",
            "[00:12.400 --> 00:14.600]  Like people thought we were batshit insane.\n",
            "[00:14.600 --> 00:15.300]  Yeah.\n",
            "[00:15.300 --> 00:18.200]  You know, like I remember at the time,\n",
            "[00:18.200 --> 00:24.300]  a eminent AI scientist at a large industrial AI lab\n",
            "[00:24.300 --> 00:27.100]  was like DMing individual reporters,\n",
            "[00:27.100 --> 00:29.700]  being like, you know, these people aren't very good\n",
            "[00:29.700 --> 00:31.500]  and it's ridiculous to talk about AGI\n",
            "[00:31.500 --> 00:33.100]  and I can't believe you're giving them time of day.\n",
            "[00:33.100 --> 00:36.100]  And it's like that was the level of like pettiness\n",
            "[00:36.100 --> 00:38.500]  and rancor in the field at a new group of people saying\n",
            "[00:38.500 --> 00:39.700]  we're going to try to build AGI.\n",
            "[00:40.400 --> 00:43.700]  So OpenAI and DeepMind was a small collection of folks\n",
            "[00:43.700 --> 00:46.800]  who were brave enough to talk about AGI\n",
            "[00:49.100 --> 00:50.300]  in the face of mockery.\n",
            "[00:51.100 --> 00:52.300]  We don't get mocked as much now.\n",
            "[00:53.100 --> 00:54.600]  Don't get mocked as much now.\n",
            "[00:56.900 --> 00:59.500]  The following is a conversation with Sam Altman.\n",
            "[00:59.700 --> 01:03.700]  CEO of OpenAI, the company behind GPT-4,\n",
            "[01:03.900 --> 01:08.700]  JADGPT, Dolly, Codex, and many other AI technologies,\n",
            "[01:08.800 --> 01:11.700]  which both individually and together constitute\n",
            "[01:11.700 --> 01:14.200]  some of the greatest breakthroughs in the history\n",
            "[01:14.200 --> 01:18.000]  of artificial intelligence, computing, and humanity in general.\n",
            "[01:18.900 --> 01:22.000]  Please allow me to say a few words about the possibilities\n",
            "[01:22.200 --> 01:25.200]  and the dangers of AI in this current moment\n",
            "[01:25.200 --> 01:26.900]  in the history of human civilization.\n",
            "[01:27.500 --> 01:29.100]  I believe it is a critical moment.\n",
            "[01:29.600 --> 01:33.100]  We stand on the precipice of fundamental societal transformation\n",
            "[01:33.400 --> 01:37.100]  where soon, nobody knows when, but many, including me,\n",
            "[01:37.100 --> 01:38.800]  believe it's within our lifetime.\n",
            "[01:39.400 --> 01:42.300]  The collective intelligence of the human species\n",
            "[01:42.700 --> 01:46.500]  begins to pale in comparison by many orders of magnitude\n",
            "[01:46.800 --> 01:50.700]  to the general superintelligence in the AI systems\n",
            "[01:50.700 --> 01:54.200]  we build and deploy at scale.\n",
            "[01:55.300 --> 01:58.100]  This is both exciting and terrifying.\n",
            "[01:58.800 --> 02:02.200]  It is exciting because of the innumerable applications\n",
            "[02:02.400 --> 02:07.100]  we know and don't yet know that will empower humans to create,\n",
            "[02:07.300 --> 02:11.400]  to flourish, to escape the widespread poverty and suffering\n",
            "[02:11.400 --> 02:14.700]  that exists in the world today, and to succeed\n",
            "[02:15.000 --> 02:18.700]  in that old all-too-human pursuit of happiness.\n",
            "[02:19.800 --> 02:23.600]  It is terrifying because of the power that superintelligent\n",
            "[02:23.600 --> 02:27.000]  AGI wields to destroy human civilization,\n",
            "[02:27.400 --> 02:30.000]  intentionally or unintentionally.\n",
            "[02:30.700 --> 02:35.200]  The power to suffocate the human spirit in the totalitarian way\n",
            "[02:35.200 --> 02:40.300]  of George Orwell's 1984 or the pleasure-fueled mass hysteria\n",
            "[02:40.700 --> 02:45.100]  of Brave New World, where, as Huxley saw it, people come\n",
            "[02:45.100 --> 02:48.800]  to love their oppression, to adore the technologies\n",
            "[02:49.100 --> 02:51.600]  that undo their capacities to think.\n",
            "[02:52.600 --> 02:56.900]  That is why these conversations with the leaders, engineers,\n",
            "[02:56.900 --> 03:01.400]  and philosophers, both optimists and cynics, is important now.\n",
            "[03:02.800 --> 03:05.500]  These are not merely technical conversations about AI.\n",
            "[03:05.900 --> 03:09.800]  These are conversations about power, about companies, institutions,\n",
            "[03:09.800 --> 03:13.400]  and political systems that deploy, check, and balance this power,\n",
            "[03:14.000 --> 03:18.400]  about distributed economic systems that incentivize the safety\n",
            "[03:18.400 --> 03:20.600]  and human alignment of this power,\n",
            "[03:20.600 --> 03:23.700]  about the psychology of the engineers and leaders that deploy\n",
            "[03:23.700 --> 03:29.000]  AGI, and about the history of human nature, our capacity\n",
            "[03:29.000 --> 03:32.200]  for good and evil at scale.\n",
            "[03:33.300 --> 03:37.500]  I'm deeply honored to have gotten to know and to have spoken\n",
            "[03:37.500 --> 03:41.700]  with on and off the mic with many folks who now work at OpenAI,\n",
            "[03:42.000 --> 03:47.900]  including Sam Altman, Greg Brockman, Ilya Tsitskever, Wojciech Zaremba,\n",
            "[03:47.900 --> 03:52.800]  Andrei Karpathy, Jacob Pachaki, and many others.\n",
            "[03:53.500 --> 03:57.800]  It means the world that Sam has been totally open with me, willing\n",
            "[03:57.800 --> 04:02.800]  to have multiple conversations, including challenging ones, on and off the mic.\n",
            "[04:03.400 --> 04:06.700]  I will continue to have these conversations to both celebrate\n",
            "[04:06.900 --> 04:11.400]  the incredible accomplishments of the AI community and to steel man\n",
            "[04:11.400 --> 04:15.200]  the critical perspective on major decisions various companies\n",
            "[04:15.200 --> 04:16.200]  and leaders make.\n",
            "[04:16.700 --> 04:20.800]  Always with the goal of trying to help in my small way.\n",
            "[04:21.300 --> 04:24.600]  If I fail, I will work hard to improve.\n",
            "[04:25.300 --> 04:26.100]  I love you all.\n",
            "[04:27.300 --> 04:29.100]  This is the Lex Freedman podcast.\n",
            "[04:29.300 --> 04:32.100]  To support it, please check out our sponsors in the description.\n",
            "[04:32.400 --> 04:35.700]  And now, dear friends, here's Sam Altman.\n",
            "[04:37.000 --> 04:39.400]  High level, what is GPT for?\n",
            "[04:39.500 --> 04:42.700]  How does it work and what to use most amazing about it?\n",
            "[04:43.300 --> 04:46.100]  It's a system that we'll look back at and say was a very early\n",
            "[04:46.200 --> 04:49.500]  AI and it will it's slow.\n",
            "[04:49.700 --> 04:50.600]  It's buggy.\n",
            "[04:51.100 --> 04:52.800]  It doesn't do a lot of things very well.\n",
            "[04:53.700 --> 04:55.600]  But neither did the very earliest computers.\n",
            "[04:56.600 --> 05:00.700]  And they still pointed a path to something that was going to be really\n",
            "[05:00.700 --> 05:03.900]  important in our lives, even though it took a few decades to evolve.\n",
            "[05:04.300 --> 05:06.200]  Do you think this is a pivotal moment?\n",
            "[05:06.400 --> 05:10.800]  Like out of all the versions of GPT 50 years from now, when they\n",
            "[05:10.800 --> 05:14.300]  look back at an early system, that was really kind of a leap.\n",
            "[05:14.700 --> 05:18.600]  You know, in a Wikipedia page about the history of artificial intelligence,\n",
            "[05:18.600 --> 05:20.400]  which which of the GPTs would they put?\n",
            "[05:20.500 --> 05:21.600]  That is a good question.\n",
            "[05:21.600 --> 05:24.900]  I sort of think of progress as this continual exponential.\n",
            "[05:25.300 --> 05:29.200]  It's not like we could say here was the moment where AI went from\n",
            "[05:29.400 --> 05:30.700]  not happening to happening.\n",
            "[05:31.300 --> 05:34.600]  And I'd have a very hard time like pinpointing a single thing.\n",
            "[05:34.600 --> 05:36.300]  I think it's this very continual curve.\n",
            "[05:37.300 --> 05:40.500]  Will the history books write about GPT one or two or three or four or seven?\n",
            "[05:41.300 --> 05:42.300]  That's for them to decide.\n",
            "[05:42.300 --> 05:43.400]  I don't I don't really know.\n",
            "[05:43.400 --> 05:43.900]  I think.\n",
            "[05:45.100 --> 05:49.700]  If I had to pick some moment from what we've seen so far, I'd sort of pick\n",
            "[05:49.700 --> 05:53.300]  chat GPT, you know, it wasn't the underlying model that mattered.\n",
            "[05:53.300 --> 05:56.600]  It was the usability of it, both the RLHF and the interface to it.\n",
            "[05:57.500 --> 05:58.900]  What is chat GPT?\n",
            "[05:58.900 --> 06:00.200]  What is RLHF?\n",
            "[06:00.900 --> 06:03.000]  Reinforcement learning with human feedback.\n",
            "[06:03.000 --> 06:07.900]  What was that little magic ingredient to the dish that made\n",
            "[06:07.900 --> 06:09.800]  it so much more delicious?\n",
            "[06:10.500 --> 06:16.000]  So we train these models on a lot of text data and in that process, they\n",
            "[06:16.000 --> 06:20.500]  learn the underlying something about the underlying representations of\n",
            "[06:20.500 --> 06:26.000]  what's in here or in there and they can do amazing things.\n",
            "[06:26.300 --> 06:29.500]  But when you first play with that base model that we call it after you\n",
            "[06:29.500 --> 06:32.400]  finish training, it can do very well on evals.\n",
            "[06:32.400 --> 06:33.500]  It can pass tests.\n",
            "[06:33.500 --> 06:37.500]  It can do a lot of, you know, there's knowledge in there, but it's not very\n",
            "[06:37.500 --> 06:41.300]  useful or at least it's not easy to use, let's say.\n",
            "[06:41.800 --> 06:45.000]  And RLHF is how we take some human feedback.\n",
            "[06:45.400 --> 06:49.700]  The simplest version of this is show two outputs, ask which one is better\n",
            "[06:49.700 --> 06:54.200]  than the other, which one the human raters prefer, and then feed that\n",
            "[06:54.200 --> 06:56.000]  back into the model with reinforcement learning.\n",
            "[06:56.400 --> 07:01.000]  And that process works remarkably well with, in my opinion, remarkably\n",
            "[07:01.000 --> 07:04.100]  little data to make the model more useful.\n",
            "[07:04.400 --> 07:09.100]  So RLHF is how we align the model to what humans want it to do.\n",
            "[07:09.500 --> 07:14.400]  So there's a giant language model that's trained in a giant data set to\n",
            "[07:14.400 --> 07:17.700]  create this kind of background wisdom knowledge that's contained within\n",
            "[07:17.700 --> 07:24.600]  the internet and then somehow adding a little bit of human guidance on top\n",
            "[07:24.600 --> 07:29.600]  of it through this process makes it seem so much more awesome.\n",
            "[07:30.700 --> 07:32.500]  Maybe just because it's much easier to use.\n",
            "[07:32.500 --> 07:33.900]  It's much easier to get what you want.\n",
            "[07:33.900 --> 07:37.500]  You get it right more often the first time and ease of use matters a lot,\n",
            "[07:37.500 --> 07:39.900]  even if the base capability was there before.\n",
            "[07:40.400 --> 07:46.100]  And like a feeling like it understood the question you're asking or like\n",
            "[07:46.300 --> 07:49.100]  it feels like you're kind of on the same page.\n",
            "[07:49.100 --> 07:50.000]  It's trying to help you.\n",
            "[07:50.700 --> 07:52.000]  It's the feeling of alignment.\n",
            "[07:52.000 --> 07:52.300]  Yes.\n",
            "[07:52.300 --> 07:54.400]  I mean, that could be a more technical term for it.\n",
            "[07:55.200 --> 07:58.000]  And you're saying that not much data is required for that.\n",
            "[07:58.000 --> 07:59.700]  Not much human supervision is required for that.\n",
            "[07:59.700 --> 08:06.300]  To be fair, we understand the science of this part at a much earlier stage\n",
            "[08:06.300 --> 08:09.300]  than we do the science of creating these large pre-trained models in the\n",
            "[08:09.300 --> 08:11.300]  first place, but yes, less data, much less data.\n",
            "[08:11.600 --> 08:12.500]  That's so interesting.\n",
            "[08:12.500 --> 08:16.000]  The science of human guidance.\n",
            "[08:18.100 --> 08:19.700]  That's a very interesting science.\n",
            "[08:20.000 --> 08:23.500]  It's going to be a very important science to understand how to make it\n",
            "[08:23.500 --> 08:28.500]  usable, how to make it wise, how to make it ethical, how to make it\n",
            "[08:28.500 --> 08:31.200]  aligned in terms of all the kinds of stuff we think about.\n",
            "[08:34.400 --> 08:37.500]  And it matters which are the humans and what is the process of incorporating\n",
            "[08:37.500 --> 08:40.000]  that human feedback and what are you asking the humans?\n",
            "[08:40.000 --> 08:40.800]  Is it two things?\n",
            "[08:40.800 --> 08:42.100]  Are you asking them to rank things?\n",
            "[08:42.400 --> 08:46.900]  What aspects are you letting or asking the humans to focus in on?\n",
            "[08:46.900 --> 08:48.100]  It's really fascinating.\n",
            "[08:48.300 --> 08:54.400]  But how, what is the data set it's trained on?\n",
            "[08:54.500 --> 08:57.300]  Can you kind of loosely speak to the enormity of this data set?\n",
            "[08:57.300 --> 08:58.200]  The pre-training data set?\n",
            "[08:58.200 --> 08:59.300]  The pre-training data set.\n",
            "[09:00.400 --> 09:03.400]  We spend a huge amount of effort pulling that together from many different\n",
            "[09:03.400 --> 09:04.100]  sources.\n",
            "[09:04.600 --> 09:09.100]  There's like a lot of, there are open source databases of information.\n",
            "[09:09.800 --> 09:11.600]  We get stuff via partnerships.\n",
            "[09:11.600 --> 09:12.700]  There's things on the internet.\n",
            "[09:13.400 --> 09:16.100]  It's a lot of our work is building a great data set.\n",
            "[09:17.200 --> 09:19.400]  How much of it is the memes subreddit?\n",
            "[09:19.800 --> 09:20.500]  Not very much.\n",
            "[09:20.900 --> 09:22.300]  Maybe it'd be more fun if it were more.\n",
            "[09:23.600 --> 09:27.600]  So some of it is Reddit, some of it is news sources, all like a huge number\n",
            "[09:27.600 --> 09:28.800]  of newspapers.\n",
            "[09:29.400 --> 09:30.700]  There's like the general web.\n",
            "[09:31.100 --> 09:34.100]  There's a lot of content in the world more than I think most people think.\n",
            "[09:34.400 --> 09:37.700]  Yeah, there is like too much.\n",
            "[09:38.300 --> 09:41.800]  Like where like the task is not to find stuff but to filter out.\n",
            "[09:41.800 --> 09:42.200]  Yeah.\n",
            "[09:42.200 --> 09:42.500]  Right.\n",
            "[09:42.500 --> 09:42.800]  Yeah.\n",
            "[09:43.600 --> 09:45.300]  Was, is there a magic to that?\n",
            "[09:45.300 --> 09:48.000]  Because that seems, there seems to be several components to solve.\n",
            "[09:48.900 --> 09:53.000]  The, the design of the, you could say algorithm.\n",
            "[09:53.000 --> 09:55.600]  So like the architecture of the neural networks, maybe the size of the\n",
            "[09:55.600 --> 09:56.400]  neural network.\n",
            "[09:56.600 --> 09:58.200]  There's the selection of the data.\n",
            "[09:59.200 --> 10:04.700]  There's the, the human supervised aspect of it with, you know, RL with\n",
            "[10:04.700 --> 10:05.600]  human feedback.\n",
            "[10:06.100 --> 10:06.300]  Yeah.\n",
            "[10:06.300 --> 10:10.200]  I think one thing that is not that well understood about creation of this\n",
            "[10:10.200 --> 10:14.400]  final product, like what it takes to make GBT for the version of it we\n",
            "[10:14.400 --> 10:16.900]  actually ship out and that you get to use inside of Chad GBT.\n",
            "[10:17.300 --> 10:22.000]  The number of pieces that have to all come together and then we have to\n",
            "[10:22.000 --> 10:26.000]  figure out either new ideas or just execute existing ideas really well.\n",
            "[10:26.400 --> 10:28.200]  At every stage of this pipeline.\n",
            "[10:29.100 --> 10:30.300]  There's quite a lot that goes into it.\n",
            "[10:30.800 --> 10:32.000]  So there's a lot of problem solving.\n",
            "[10:32.000 --> 10:37.500]  Like you've already said for GBT four in the blog post and in general,\n",
            "[10:38.600 --> 10:42.500]  there's already kind of a maturity that's happening on some of these\n",
            "[10:42.500 --> 10:47.400]  steps, like being able to predict before doing the full training of\n",
            "[10:47.400 --> 10:48.500]  how the model will behave.\n",
            "[10:48.500 --> 10:51.700]  Isn't that so remarkable by the way that there's like, you know, there's\n",
            "[10:51.700 --> 10:54.800]  like a lot of science that lets you predict for these inputs.\n",
            "[10:54.800 --> 10:57.300]  Here's what's going to come out the other end.\n",
            "[10:57.300 --> 10:59.600]  Like here's the level of intelligence you can expect.\n",
            "[10:59.700 --> 11:02.300]  Is it close to a science or is it still?\n",
            "[11:03.600 --> 11:08.000]  Because you said the word law in science, which are very ambitious terms.\n",
            "[11:08.000 --> 11:08.500]  Close to.\n",
            "[11:09.300 --> 11:10.100]  Close to it, right?\n",
            "[11:10.700 --> 11:11.300]  Be accurate.\n",
            "[11:11.300 --> 11:11.700]  Yes.\n",
            "[11:11.700 --> 11:15.600]  I'll say it's way more scientific than I ever would have dared to imagine.\n",
            "[11:15.700 --> 11:21.700]  So you can really know the peculiar characteristics of the fully trained\n",
            "[11:21.700 --> 11:23.700]  system from just a little bit of training.\n",
            "[11:24.000 --> 11:27.400]  You know, like any new branch of science, there's we're going to discover\n",
            "[11:27.400 --> 11:29.500]  new things that don't fit the data and have to come up with better\n",
            "[11:29.500 --> 11:33.600]  explanations and you know, that is the ongoing process of discovering\n",
            "[11:33.600 --> 11:37.400]  science, but with what we know now, even what we had in that GPT four\n",
            "[11:37.400 --> 11:41.600]  blog post, like I think we should all just like be in awe of how amazing\n",
            "[11:41.600 --> 11:44.100]  it is that we can even predict to this current level.\n",
            "[11:44.500 --> 11:48.400]  Yeah, you can look at a one-year-old baby and predict how it's going\n",
            "[11:48.400 --> 11:49.600]  to do on the SATs.\n",
            "[11:49.800 --> 11:50.300]  I don't know.\n",
            "[11:51.000 --> 11:54.700]  Uh, seemingly an equivalent one, but because here we can actually in\n",
            "[11:54.700 --> 11:59.600]  detail introspect various aspects of the system you can predict that said,\n",
            "[11:59.600 --> 12:04.500]  uh, just to jump around, you said the language model that is GPT four.\n",
            "[12:05.300 --> 12:11.200]  It learns in quotes, something, uh, in terms of science and the art and\n",
            "[12:11.200 --> 12:15.620]  so on is there within open AI within like folks like yourself and\n",
            "[12:15.620 --> 12:19.520]  Elias discover and the engineers a deeper and deeper understanding of\n",
            "[12:19.720 --> 12:26.120]  what that something is or is it still a kind of, um, beautiful magical\n",
            "[12:26.120 --> 12:26.620]  mystery?\n",
            "[12:28.020 --> 12:32.220]  Well, there's all these different evals that we could talk about and\n",
            "[12:32.420 --> 12:33.020]  what's an evil.\n",
            "[12:33.220 --> 12:37.420]  Oh, like how we, how we measure a model as we're training it after\n",
            "[12:37.420 --> 12:40.220]  we've trained it and say like, you know, how good is this at some set\n",
            "[12:40.220 --> 12:43.020]  of tasks and also just in a small tangent, thank you for sort of\n",
            "[12:43.020 --> 12:45.920]  open sourcing the evaluation process.\n",
            "[12:45.920 --> 12:47.620]  Yeah, I think that'll be really helpful.\n",
            "[12:48.420 --> 12:54.320]  Um, but the one that really matters is, you know, we pour all of this\n",
            "[12:54.320 --> 12:58.420]  effort and money and time into this thing and then what it comes out\n",
            "[12:58.420 --> 13:00.820]  with, like how useful is that to people?\n",
            "[13:01.220 --> 13:02.720]  How much delight does that bring people?\n",
            "[13:02.720 --> 13:06.220]  How much does that help them create a much better world, new science,\n",
            "[13:06.220 --> 13:07.920]  new products, new services, whatever.\n",
            "[13:08.520 --> 13:14.320]  And that's the one that matters and understanding for a particular set\n",
            "[13:14.320 --> 13:17.920]  of inputs, like how much value and utility to provide to people.\n",
            "[13:18.320 --> 13:20.720]  I think we are understanding that better.\n",
            "[13:21.220 --> 13:27.220]  Um, do we understand everything about why the model does one thing and\n",
            "[13:27.220 --> 13:28.020]  not one other thing?\n",
            "[13:28.320 --> 13:34.320]  Certainly not, not always, but I would say we are pushing back like the\n",
            "[13:34.320 --> 13:36.520]  fog of war more and more.\n",
            "[13:36.520 --> 13:41.320]  And we are, you know, it took a lot of understanding to make GPT-4 for example.\n",
            "[13:41.820 --> 13:44.820]  But I'm not even sure we can ever fully understand.\n",
            "[13:44.820 --> 13:47.620]  Like you said, you would understand by asking questions essentially,\n",
            "[13:48.020 --> 13:53.520]  because it's compressing all of the web, like a huge sloth of the web into\n",
            "[13:53.820 --> 14:00.120]  a small number of parameters into one organized black box that is human wisdom.\n",
            "[14:01.220 --> 14:01.820]  What is that?\n",
            "[14:01.920 --> 14:02.920]  Human knowledge, let's say.\n",
            "[14:03.620 --> 14:04.320]  Human knowledge.\n",
            "[14:05.320 --> 14:06.320]  It's a good difference.\n",
            "[14:07.620 --> 14:09.720]  Is there a difference between knowledge?\n",
            "[14:10.020 --> 14:11.620]  There's facts and there's wisdom.\n",
            "[14:11.620 --> 14:14.420]  And I feel like GPT-4 can be also full of wisdom.\n",
            "[14:14.820 --> 14:16.320]  What's the leap from facts to wisdom?\n",
            "[14:16.520 --> 14:20.620]  You know, a funny thing about the way we're training these models is I\n",
            "[14:20.620 --> 14:25.820]  suspect too much of the processing power, for lack of a better word, is\n",
            "[14:25.820 --> 14:31.320]  going into using the model as a database instead of using the model as a reasoning engine.\n",
            "[14:31.320 --> 14:34.820]  The thing that's really amazing about this system is that it, for some definition\n",
            "[14:34.820 --> 14:37.420]  of reasoning, and we could of course quibble about it, and there's plenty for\n",
            "[14:37.420 --> 14:42.020]  which definitions this wouldn't be accurate, but for some definition, it can do\n",
            "[14:42.020 --> 14:43.020]  some kind of reasoning.\n",
            "[14:43.320 --> 14:47.020]  And you know, maybe like the scholars and the experts and like the armchair\n",
            "[14:47.020 --> 14:49.420]  quarterbacks on Twitter would say, no, it can't.\n",
            "[14:49.420 --> 14:50.420]  You're misusing the word.\n",
            "[14:50.420 --> 14:51.720]  You're, you know, whatever, whatever.\n",
            "[14:52.120 --> 14:55.520]  But I think most people who have used the system would say, okay, it's doing\n",
            "[14:55.520 --> 14:56.820]  something in this direction.\n",
            "[14:56.820 --> 15:04.320]  And I think that's remarkable and the thing that's most exciting and somehow\n",
            "[15:04.320 --> 15:12.120]  out of ingesting human knowledge, it's coming up with this reasoning capability.\n",
            "[15:12.120 --> 15:13.520]  However, we want to talk about that.\n",
            "[15:14.620 --> 15:19.120]  Now, in some senses, I think that will be additive to human wisdom.\n",
            "[15:19.620 --> 15:23.220]  And in some other senses, you can use GPT-4 for all kinds of things.\n",
            "[15:23.220 --> 15:27.020]  And in some other senses, you can use GPT-4 for all kinds of things and say\n",
            "[15:27.020 --> 15:29.120]  that it appears that there's no wisdom in here whatsoever.\n",
            "[15:30.820 --> 15:33.920]  Yeah, at least in interaction with humans, it seems to possess wisdom,\n",
            "[15:34.020 --> 15:37.520]  especially when there's a continuous interaction of multiple prompts.\n",
            "[15:37.820 --> 15:45.820]  So I think what on the ChadGPT site, it says the dialogue format makes it\n",
            "[15:45.820 --> 15:50.120]  possible for ChadGPT to answer follow-up questions, admit its mistakes,\n",
            "[15:50.320 --> 15:53.220]  challenge incorrect premises and reject inappropriate requests.\n",
            "[15:53.520 --> 15:57.620]  But also there's a feeling like it's struggling with ideas.\n",
            "[15:58.220 --> 16:01.220]  Yeah, it's always tempting to anthropomorphize this stuff too much,\n",
            "[16:01.220 --> 16:02.520]  but I also feel that way.\n",
            "[16:03.020 --> 16:08.320]  Maybe I'll take a small tangent towards Jordan Peterson who posted on Twitter\n",
            "[16:09.120 --> 16:12.220]  this kind of political question.\n",
            "[16:12.920 --> 16:16.020]  Everyone has a different question they want to ask ChadGPT first, right?\n",
            "[16:17.020 --> 16:20.620]  Like the different directions you want to try the dark thing.\n",
            "[16:20.620 --> 16:23.220]  It somehow says a lot about people when they try first.\n",
            "[16:23.220 --> 16:23.820]  The first thing.\n",
            "[16:24.420 --> 16:25.120]  Oh no.\n",
            "[16:25.620 --> 16:26.220]  Oh no.\n",
            "[16:26.220 --> 16:28.620]  We don't have to review what I asked first.\n",
            "[16:29.420 --> 16:32.620]  I of course ask mathematical questions and never ask anything dark.\n",
            "[16:33.820 --> 16:40.020]  But Jordan asked it to say positive things about the current President\n",
            "[16:40.020 --> 16:42.420]  Joe Biden and the previous President Donald Trump.\n",
            "[16:42.920 --> 16:49.920]  And then he asked GPT as a follow-up to say how many characters, how long is\n",
            "[16:49.920 --> 16:51.520]  the string that you generated?\n",
            "[16:51.520 --> 16:56.520]  And he showed that the response that contained positive things about Biden\n",
            "[16:56.520 --> 17:00.120]  was much longer or longer than that about Trump.\n",
            "[17:00.720 --> 17:04.720]  And Jordan asked the system to, can you rewrite it with an equal number,\n",
            "[17:04.920 --> 17:08.420]  equal length string, which all of this is just remarkable to me that it\n",
            "[17:08.420 --> 17:11.320]  understood, but it failed to do it.\n",
            "[17:12.520 --> 17:21.320]  And it was interest that GPT, ChadGPT, I think that was 3.5 based, was kind\n",
            "[17:21.320 --> 17:26.820]  of introspective about, yeah, it seems like I failed to do the job correctly.\n",
            "[17:27.720 --> 17:34.620]  And Jordan framed it as ChadGPT was lying and aware that it's lying.\n",
            "[17:35.520 --> 17:39.420]  But that framing, that's a human anthropomorphization, I think.\n",
            "[17:40.120 --> 17:47.420]  But that kind of, there seemed to be a struggle within GPT to understand\n",
            "[17:50.120 --> 17:57.820]  how to do, like what it means to generate a text of the same length in an\n",
            "[17:57.820 --> 18:03.420]  answer to a question and also in a sequence of prompts, how to understand\n",
            "[18:03.420 --> 18:08.120]  that it failed to do so previously and where it succeeded and all of those\n",
            "[18:08.120 --> 18:11.620]  like multi, like parallel reasonings that it's doing.\n",
            "[18:12.120 --> 18:13.620]  It just seems like it's struggling.\n",
            "[18:13.620 --> 18:15.620]  So two separate things going on here.\n",
            "[18:15.720 --> 18:19.720]  Number one, some of the things that seem like they should be obvious\n",
            "[18:19.720 --> 18:21.820]  and easy, these models really struggle with.\n",
            "[18:22.120 --> 18:24.820]  So I haven't seen this particular example, but counting characters,\n",
            "[18:24.820 --> 18:28.220]  counting words, that sort of stuff, that is hard for these models to do\n",
            "[18:28.220 --> 18:29.620]  well the way they're architected.\n",
            "[18:30.220 --> 18:31.220]  That won't be very accurate.\n",
            "[18:32.220 --> 18:36.920]  Second, we are building in public and we are putting out technology\n",
            "[18:37.420 --> 18:40.220]  because we think it is important for the world to get access to this\n",
            "[18:40.220 --> 18:44.120]  early, to shape the way it's going to be developed, to help us find the\n",
            "[18:44.120 --> 18:45.520]  good things and the bad things.\n",
            "[18:45.720 --> 18:48.220]  And every time we put out a new model, and we've just really felt this\n",
            "[18:48.220 --> 18:52.320]  with GPT-4 this week, the collective intelligence and ability of the\n",
            "[18:52.320 --> 18:56.020]  outside world helps us discover things we cannot imagine we could have\n",
            "[18:56.020 --> 19:00.520]  never done internally and both like great things that the model can do,\n",
            "[19:00.520 --> 19:02.820]  new capabilities and real weaknesses we have to fix.\n",
            "[19:03.320 --> 19:09.020]  And so this iterative process of putting things out, finding the great\n",
            "[19:09.020 --> 19:12.920]  parts, the bad parts, improving them quickly, and giving people time\n",
            "[19:12.920 --> 19:16.920]  to feel the technology and shape it with us and provide feedback,\n",
            "[19:17.120 --> 19:18.320]  we believe is really important.\n",
            "[19:18.720 --> 19:22.320]  The trade-off of that is the trade-off of building in public, which is we\n",
            "[19:22.320 --> 19:24.920]  put out things that are going to be deeply imperfect.\n",
            "[19:25.120 --> 19:27.220]  We want to make our mistakes while the stakes are low.\n",
            "[19:27.420 --> 19:29.520]  We want to get it better and better each rep.\n",
            "[19:30.220 --> 19:36.720]  But the like the bias of chat GPT when it launched with 3.5 was not\n",
            "[19:36.720 --> 19:38.420]  something that I certainly felt proud of.\n",
            "[19:39.220 --> 19:40.720]  It's gotten much better with GPT-4.\n",
            "[19:40.720 --> 19:43.320]  Many of the critics, and I really respect this, have said, hey, a lot\n",
            "[19:43.320 --> 19:46.520]  of the problems that I had with 3.5 are much better in 4.\n",
            "[19:47.720 --> 19:51.420]  But also no two people are ever going to agree that one single model\n",
            "[19:51.420 --> 19:52.820]  is unbiased on every topic.\n",
            "[19:53.320 --> 19:57.720]  And I think the answer there is just going to be to give users more\n",
            "[19:57.920 --> 20:00.320]  personalized control, granular control over time.\n",
            "[20:01.620 --> 20:06.020]  And I should say on this point, I've gotten to know Jordan Peterson.\n",
            "[20:06.420 --> 20:12.420]  And I tried to talk to GPT-4 about Jordan Peterson and I asked it\n",
            "[20:12.520 --> 20:14.220]  if Jordan Peterson is a fascist.\n",
            "[20:15.520 --> 20:17.720]  First of all, it gave context.\n",
            "[20:18.020 --> 20:21.320]  It described actual like description of who Jordan Peterson is, his\n",
            "[20:21.320 --> 20:22.920]  career, psychologist, and so on.\n",
            "[20:23.420 --> 20:30.220]  It stated that some number of people have called Jordan Peterson\n",
            "[20:30.220 --> 20:34.920]  a fascist, but there is no factual grounding to those claims.\n",
            "[20:34.920 --> 20:38.820]  And it described a bunch of stuff that Jordan believes, like he's been\n",
            "[20:38.820 --> 20:46.020]  an outspoken critic of various totalitarian ideologies and he\n",
            "[20:46.020 --> 20:56.420]  believes in individualism and various freedoms that contradict the\n",
            "[20:56.420 --> 20:58.220]  ideology of fascism and so on.\n",
            "[20:58.220 --> 21:00.720]  And then it goes on and on like really nicely and it wraps it up.\n",
            "[21:00.820 --> 21:02.420]  It's like a, it's a college essay.\n",
            "[21:02.420 --> 21:04.020]  I was like, damn.\n",
            "[21:04.020 --> 21:08.320]  One thing that I hope these models can do is bring some\n",
            "[21:08.320 --> 21:09.420]  nuance back to the world.\n",
            "[21:09.420 --> 21:11.320]  Yes, it felt, it felt really nuanced.\n",
            "[21:11.320 --> 21:14.920]  You know, Twitter kind of destroyed some and maybe we can get some back now.\n",
            "[21:15.120 --> 21:16.320]  That really is exciting to me.\n",
            "[21:16.320 --> 21:21.620]  Like for example, I asked, of course, you know, did the\n",
            "[21:22.520 --> 21:24.020]  COVID virus leak from a lab?\n",
            "[21:24.420 --> 21:27.320]  Again, answer, very nuanced.\n",
            "[21:27.620 --> 21:28.820]  There's two hypotheses.\n",
            "[21:28.920 --> 21:30.120]  It like described them.\n",
            "[21:30.420 --> 21:33.520]  It described the amount of data that's available for each.\n",
            "[21:33.620 --> 21:36.820]  It was like, it was like a breath of fresh air.\n",
            "[21:37.120 --> 21:39.720]  When I was a little kid, I thought building AI, we didn't\n",
            "[21:39.720 --> 21:40.820]  really call it AGI at the time.\n",
            "[21:40.820 --> 21:42.520]  I thought building AI would be like the coolest thing ever.\n",
            "[21:42.520 --> 21:44.720]  I never really thought I would get the chance to work on it.\n",
            "[21:45.020 --> 21:48.020]  But if you had told me that not only I would get the chance to work on it,\n",
            "[21:48.220 --> 21:53.520]  but that after making like a very, very larval proto AGI thing, that\n",
            "[21:53.520 --> 21:57.420]  the thing I'd have to spend my time on is, you know, trying to like\n",
            "[21:57.420 --> 22:00.320]  argue with people about whether the number of characters it said, nice\n",
            "[22:00.320 --> 22:03.420]  things about one person was different than the number of characters that\n",
            "[22:03.420 --> 22:04.720]  said nice about some other person.\n",
            "[22:04.920 --> 22:07.420]  If you hand people an AGI and that's what they want to do, I wouldn't\n",
            "[22:07.420 --> 22:11.420]  have believed you, but I understand it more now and I do have empathy for it.\n",
            "[22:12.220 --> 22:15.620]  So what you're implying in that statement is we took such giant\n",
            "[22:15.620 --> 22:19.320]  leaps on the big stuff and we're complaining or arguing about small stuff.\n",
            "[22:19.420 --> 22:21.220]  Well, the small stuff is the big stuff in aggregate.\n",
            "[22:21.220 --> 22:21.820]  So I get it.\n",
            "[22:21.820 --> 22:29.020]  It's just like I, and I also like, I get why this is such an important issue.\n",
            "[22:29.020 --> 22:35.720]  This is a really important issue, but that somehow we like, somehow\n",
            "[22:35.720 --> 22:39.020]  this is the thing that we get caught up in versus like, what is\n",
            "[22:39.020 --> 22:41.020]  this going to mean for our future?\n",
            "[22:41.020 --> 22:44.520]  Now, maybe you say this is critical to what this is going to mean for our\n",
            "[22:44.520 --> 22:47.320]  future, the thing that it says more characters about this person than\n",
            "[22:47.320 --> 22:50.620]  this person and who's deciding that and how it's being decided and how\n",
            "[22:50.620 --> 22:52.020]  the users get control over that.\n",
            "[22:52.620 --> 22:55.220]  Maybe that is the most important issue, but I wouldn't have\n",
            "[22:55.220 --> 22:57.520]  guessed it at the time when I was like an eight year old.\n",
            "[23:00.520 --> 23:05.920]  Yeah, I mean there is, and you do, there's folks at OpenAI, including\n",
            "[23:05.920 --> 23:09.620]  yourself that do see the importance of these issues to discuss about them\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **Run the model** üöÄ\n",
        "\n",
        "#@markdown Run this cell to execute the transcription of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "\n",
        "#@markdown ## **Parameters** ‚öôÔ∏è\n",
        "\n",
        "#@markdown ### **Behavior control**\n",
        "#@markdown ---\n",
        "language = \"English\" #@param ['Auto detection', 'Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bashkir', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Castilian', 'Catalan', 'Chinese', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Faroese', 'Finnish', 'Flemish', 'French', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hungarian', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Lao', 'Latin', 'Latvian', 'Letzeburgesch', 'Lingala', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Moldavian', 'Moldovan', 'Mongolian', 'Myanmar', 'Nepali', 'Norwegian', 'Nynorsk', 'Occitan', 'Panjabi', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Pushto', 'Romanian', 'Russian', 'Sanskrit', 'Serbian', 'Shona', 'Sindhi', 'Sinhala', 'Sinhalese', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tibetan', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'Uzbek', 'Valencian', 'Vietnamese', 'Welsh', 'Yiddish', 'Yoruba']\n",
        "#@markdown > Language spoken in the audio, use `Auto detection` to let Whisper detect the language.\n",
        "#@markdown ---\n",
        "verbose = 'Live transcription' #@param ['Live transcription', 'Progress bar', 'None']\n",
        "#@markdown > Whether to print out the progress and debug messages.\n",
        "#@markdown ---\n",
        "output_format = 'all' #@param ['txt', 'vtt', 'srt', 'tsv', 'json', 'all']\n",
        "#@markdown > Type of file to generate to record the transcription.\n",
        "#@markdown ---\n",
        "task = 'transcribe' #@param ['transcribe', 'translate']\n",
        "#@markdown > Whether to perform X->X speech recognition (`transcribe`) or X->English translation (`translate`).\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown <br/>\n",
        "\n",
        "#@markdown ### **Optional: Fine tunning**\n",
        "#@markdown ---\n",
        "temperature = 0.15 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "#@markdown > Temperature to use for sampling.\n",
        "#@markdown ---\n",
        "temperature_increment_on_fallback = 0.2 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "#@markdown > Temperature to increase when falling back when the decoding fails to meet either of the thresholds below.\n",
        "#@markdown ---\n",
        "best_of = 5 #@param {type:\"integer\"}\n",
        "#@markdown > Number of candidates when sampling with non-zero temperature.\n",
        "#@markdown ---\n",
        "beam_size = 8 #@param {type:\"integer\"}\n",
        "#@markdown > Number of beams in beam search, only applicable when temperature is zero.\n",
        "#@markdown ---\n",
        "patience = 1.0 #@param {type:\"number\"}\n",
        "#@markdown > Optional patience value to use in beam decoding, as in [*Beam Decoding with Controlled Patience*](https://arxiv.org/abs/2204.05424), the default (1.0) is equivalent to conventional beam search.\n",
        "#@markdown ---\n",
        "length_penalty = -0.05 #@param {type:\"slider\", min:-0.05, max:1, step:0.05}\n",
        "#@markdown > Optional token length penalty coefficient (alpha) as in [*Google's Neural Machine Translation System*](https://arxiv.org/abs/1609.08144), set to negative value to uses simple length normalization.\n",
        "#@markdown ---\n",
        "suppress_tokens = \"-1\" #@param {type:\"string\"}\n",
        "#@markdown > Comma-separated list of token ids to suppress during sampling; '-1' will suppress most special characters except common punctuations.\n",
        "#@markdown ---\n",
        "initial_prompt = \"\" #@param {type:\"string\"}\n",
        "#@markdown > Optional text to provide as a prompt for the first window.\n",
        "#@markdown ---\n",
        "condition_on_previous_text = True #@param {type:\"boolean\"}\n",
        "#@markdown > if True, provide the previous output of the model as a prompt for the next window; disabling may make the text inconsistent across windows, but the model becomes less prone to getting stuck in a failure loop.\n",
        "#@markdown ---\n",
        "fp16 = True #@param {type:\"boolean\"}\n",
        "#@markdown > whether to perform inference in fp16.\n",
        "#@markdown ---\n",
        "compression_ratio_threshold = 2.4 #@param {type:\"number\"}\n",
        "#@markdown > If the gzip compression ratio is higher than this value, treat the decoding as failed.\n",
        "#@markdown ---\n",
        "logprob_threshold = -1.0 #@param {type:\"number\"}\n",
        "#@markdown > If the average log probability is lower than this value, treat the decoding as failed.\n",
        "#@markdown ---\n",
        "no_speech_threshold = 0.6 #@param {type:\"slider\", min:-0.0, max:1, step:0.05}\n",
        "#@markdown > If the probability of the <|nospeech|> token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence.\n",
        "#@markdown ---\n",
        "\n",
        "verbose_lut = {\n",
        "    'Live transcription': True,\n",
        "    'Progress bar': False,\n",
        "    'None': None\n",
        "}\n",
        "\n",
        "args = dict(\n",
        "    language = (None if language == \"Auto detection\" else language),\n",
        "    verbose = verbose_lut[verbose],\n",
        "    task = task,\n",
        "    temperature = temperature,\n",
        "    temperature_increment_on_fallback = temperature_increment_on_fallback,\n",
        "    best_of = best_of,\n",
        "    beam_size = beam_size,\n",
        "    patience=patience,\n",
        "    length_penalty=(length_penalty if length_penalty>=0.0 else None),\n",
        "    suppress_tokens=suppress_tokens,\n",
        "    initial_prompt=(None if not initial_prompt else initial_prompt),\n",
        "    condition_on_previous_text=condition_on_previous_text,\n",
        "    fp16=fp16,\n",
        "    compression_ratio_threshold=compression_ratio_threshold,\n",
        "    logprob_threshold=logprob_threshold,\n",
        "    no_speech_threshold=no_speech_threshold\n",
        ")\n",
        "\n",
        "temperature = args.pop(\"temperature\")\n",
        "temperature_increment_on_fallback = args.pop(\"temperature_increment_on_fallback\")\n",
        "if temperature_increment_on_fallback is not None:\n",
        "    temperature = tuple(np.arange(temperature, 1.0 + 1e-6, temperature_increment_on_fallback))\n",
        "else:\n",
        "    temperature = [temperature]\n",
        "\n",
        "if Model.endswith(\".en\") and args[\"language\"] not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{args['language']}'; using English instead.\")\n",
        "    args[\"language\"] = \"en\"\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "    display(Markdown(f\"### {video_path_local}\"))\n",
        "\n",
        "    video_transcription = whisper.transcribe(\n",
        "        whisper_model,\n",
        "        str(video_path_local),\n",
        "        temperature=temperature,\n",
        "        **args,\n",
        "    )\n",
        "\n",
        "    # Save output\n",
        "    whisper.utils.get_writer(\n",
        "        output_format=output_format,\n",
        "        output_dir=video_path_local.parent\n",
        "    )(\n",
        "        video_transcription,\n",
        "        str(video_path_local.stem),\n",
        "        options=dict(\n",
        "            highlight_words=False,\n",
        "            max_line_count=None,\n",
        "            max_line_width=None,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    def exportTranscriptFile(ext: str):\n",
        "        local_path = video_path_local.parent / video_path_local.with_suffix(ext).name\n",
        "        export_path = drive_whisper_path / video_path_local.with_suffix(ext).name\n",
        "        shutil.copy(\n",
        "            local_path,\n",
        "            export_path\n",
        "        )\n",
        "        display(Markdown(f\"**Transcript file created: {export_path}**\"))\n",
        "\n",
        "    if output_format==\"all\":\n",
        "        for ext in ('.txt', '.vtt', '.srt', '.tsv', '.json'):\n",
        "            exportTranscriptFile(ext)\n",
        "    else:\n",
        "        exportTranscriptFile(\".\" + output_format)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ad6n1m4deAHp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}